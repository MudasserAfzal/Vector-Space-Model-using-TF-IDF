# Vector-Space-Model-using-TF-IDF
This work is done using python and ACL data of 20k documents. The sole purpose of this work is for high school students who want to familiar with NLP terms

# Dataset
here is the link: https://drive.google.com/file/d/1W311ovrv-8XF-yWNtJwzTVz3qOp8R1UH/view

This data contain nearly 20K document which are notepad files. ACL data is made up of short conversation and reports which can be use for educational purposes. In this notebook you will see that how we use this data to make huge corpus and further make vector space model (VSM)

# Libraries you need
- Numpy
- NLTK
- collections

# About the notebook
This code is done by me from scratch and i have commented each and every line which can be easily understandable. 
steps to code
- I have read the data from the txt file first and save them in a list
- Make a corpus including vocabulary words
- Find term frequency of each word (means how many time a word come in a single document)
- Find TF-IDF which help us to give weights to the words. the words which are most repeated or you can say stopwords are less prior and rare words are more prior to us.
- Make vector space model
- Test

In case of any query feel free to ask...
